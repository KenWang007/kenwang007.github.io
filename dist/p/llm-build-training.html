<!DOCTYPE html>
<html lang="zh-CN" class="page-article">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="ğŸ—ï¸ å¤§æ¨¡å‹æ¶æ„ã€è®­ç»ƒä¸éƒ¨ç½² - å…³é”®è¯: æ¶æ„, å¤§æ¨¡å‹æ¶æ„, è®­ç»ƒä¸éƒ¨ç½²">
    <meta name="keywords" content="æ¶æ„, å¤§æ¨¡å‹æ¶æ„, è®­ç»ƒä¸éƒ¨ç½²">
    <meta name="author" content="Ken Wang">
    <meta name="robots" content="index, follow">
    
    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://kenwang007.github.io/dist/p/llm-build-training.html">
    <meta property="og:title" content="ğŸ—ï¸ å¤§æ¨¡å‹æ¶æ„ã€è®­ç»ƒä¸éƒ¨ç½² - Kençš„çŸ¥è¯†åº“">
    <meta property="og:description" content="ğŸ—ï¸ å¤§æ¨¡å‹æ¶æ„ã€è®­ç»ƒä¸éƒ¨ç½² - å…³é”®è¯: æ¶æ„, å¤§æ¨¡å‹æ¶æ„, è®­ç»ƒä¸éƒ¨ç½²">
    
    <!-- Twitter -->
    <meta property="twitter:card" content="summary">
    <meta property="twitter:url" content="https://kenwang007.github.io/dist/p/llm-build-training.html">
    <meta property="twitter:title" content="ğŸ—ï¸ å¤§æ¨¡å‹æ¶æ„ã€è®­ç»ƒä¸éƒ¨ç½² - Kençš„çŸ¥è¯†åº“">
    <meta property="twitter:description" content="ğŸ—ï¸ å¤§æ¨¡å‹æ¶æ„ã€è®­ç»ƒä¸éƒ¨ç½² - å…³é”®è¯: æ¶æ„, å¤§æ¨¡å‹æ¶æ„, è®­ç»ƒä¸éƒ¨ç½²">
    
    <!-- Theme Color -->
    <meta name="theme-color" content="#6366f1">
    
    <title>ğŸ—ï¸ å¤§æ¨¡å‹æ¶æ„ã€è®­ç»ƒä¸éƒ¨ç½² - Kençš„çŸ¥è¯†åº“</title>
    <link rel="stylesheet" href="/style.css?v=2.1.2">
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22 fill=%22%236366f1%22>ğŸ“š</text></svg>">
    <link rel="canonical" href="https://kenwang007.github.io/dist/p/llm-build-training.html">
    <link rel="manifest" href="/manifest.json">
    
    <!-- RSS Feed -->
    <link rel="alternate" type="application/rss+xml" title="Kençš„çŸ¥è¯†åº“ RSS Feed" href="/rss.xml">
    
    <!-- Breadcrumb Navigation -->
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "BreadcrumbList",
      "itemListElement": [
        {
          "@type": "ListItem",
          "position": 1,
          "name": "é¦–é¡µ",
          "item": "https://kenwang007.github.io/"
        },
        {
          "@type": "ListItem",
          "position": 2,
          "name": "ğŸ—ï¸ å¤§æ¨¡å‹æ¶æ„ã€è®­ç»ƒä¸éƒ¨ç½²",
          "item": "https://kenwang007.github.io/dist/p/llm-build-training.html"
        }
      ]
    }
    </script>
    
    <!-- Article Structured Data -->
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Article",
      "headline": "ğŸ—ï¸ å¤§æ¨¡å‹æ¶æ„ã€è®­ç»ƒä¸éƒ¨ç½²",
      "description": "ğŸ—ï¸ å¤§æ¨¡å‹æ¶æ„ã€è®­ç»ƒä¸éƒ¨ç½² - å…³é”®è¯: æ¶æ„, å¤§æ¨¡å‹æ¶æ„, è®­ç»ƒä¸éƒ¨ç½²",
      "author": {
        "@type": "Person",
        "name": "Ken Wang"
      },
      "datePublished": "2026-01-25T21:05:30.745179",
      "dateModified": "2026-01-25T21:05:30.745179",
      "inLanguage": "zh-CN"
    }
    </script>
</head>
<body>
    <!-- æ˜Ÿç©ºèƒŒæ™¯ -->
    <div class="stars"></div>
    <div class="stars2"></div>
    <div class="stars3"></div>

    <!-- é¡¶éƒ¨å›ºå®šå¯¼èˆª -->
    <header class="top-nav">
        <div class="nav-container">
            <div class="logo">
                <a href="/index.html">
                    <span class="logo-text">ğŸ“š Kençš„çŸ¥è¯†åº“</span>
                </a>
            </div>
            <nav class="main-nav">
                <ul id="nav-menu" class="nav-menu">
                    <!-- åŠ¨æ€ç”Ÿæˆçš„å¯¼èˆªèœå•é¡¹ -->
                </ul>
            </nav>
        </div>
    </header>

    <!-- ä¸»å†…å®¹åŒºåŸŸ -->
    <main class="main-content">
        <!-- å·¦ä¾§å›ºå®šå…³é”®è¯ç´¢å¼• -->
        <aside class="keyword-sidebar">
            <div class="keyword-header">
                <h3>å…³é”®è¯ç´¢å¼•</h3>
            </div>
            <div class="keyword-list" id="keyword-list">
                <!-- åŠ¨æ€ç”Ÿæˆçš„å…³é”®è¯ -->
            </div>
        </aside>

        <!-- ä¸­é—´ä¸»å†…å®¹ -->
        <section class="content-area">
            <div class="content-wrapper">
                <article class="markdown-content">
                    <h1>ğŸ—ï¸ å¤§æ¨¡å‹æ¶æ„ã€è®­ç»ƒä¸éƒ¨ç½²</h1><pre>---
slug: llm-build-training
title: ğŸ—ï¸ å¤§æ¨¡å‹æ¶æ„ã€è®­ç»ƒä¸éƒ¨ç½²
---

# ğŸ—ï¸ å¤§æ¨¡å‹æ¶æ„ã€è®­ç»ƒä¸éƒ¨ç½²

## 1. å¤§æ¨¡å‹æ¶æ„ä¸è®­ç»ƒ

### 1.1 Transformer æ¶æ„è¯¦è§£

Transformer æ˜¯ç°ä»£å¤§è¯­è¨€æ¨¡å‹çš„åŸºç¡€æ¶æ„ï¼Œç”± Google åœ¨ 2017 å¹´çš„è®ºæ–‡ã€ŠAttention Is All You Needã€‹ä¸­æå‡ºã€‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Transformer æ¶æ„                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚    Encoder      â”‚      â”‚    Decoder      â”‚          â”‚
â”‚  â”‚  (ç†è§£è¾“å…¥)      â”‚  â†’   â”‚  (ç”Ÿæˆè¾“å‡º)      â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                         â”‚
â”‚  æ¯ä¸ª Block åŒ…å«ï¼š                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚  Multi-Head Self-Attention          â”‚ â† æ•æ‰ä¾èµ–å…³ç³» â”‚
â”‚  â”‚           â†“                         â”‚               â”‚
â”‚  â”‚  Add &amp; Norm (æ®‹å·®è¿æ¥ + å±‚å½’ä¸€åŒ–)     â”‚               â”‚
â”‚  â”‚           â†“                         â”‚               â”‚
â”‚  â”‚  Feed Forward Network               â”‚ â† ç‰¹å¾å˜æ¢    â”‚
â”‚  â”‚           â†“                         â”‚               â”‚
â”‚  â”‚  Add &amp; Norm                         â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 ä¸‰ç§ä¸»æµæ¶æ„

| æ¶æ„ç±»å‹ | ä»£è¡¨æ¨¡å‹ | ç‰¹ç‚¹ | é€‚ç”¨ä»»åŠ¡ |
|----------|----------|------|----------|
| **Encoder-Only** | BERT, RoBERTa | åŒå‘æ³¨æ„åŠ›ï¼Œç†è§£èƒ½åŠ›å¼º | æ–‡æœ¬åˆ†ç±»ã€NERã€é—®ç­” |
| **Decoder-Only** | GPT, LLaMA, Qwen | è‡ªå›å½’ç”Ÿæˆï¼Œå•å‘æ³¨æ„åŠ› | æ–‡æœ¬ç”Ÿæˆã€å¯¹è¯ |
| **Encoder-Decoder** | T5, BART | ç¼–ç ç†è§£ + è§£ç ç”Ÿæˆ | ç¿»è¯‘ã€æ‘˜è¦ |

```
æ¶æ„å¯¹æ¯”ï¼š

Encoder-Only (BERT):
  è¾“å…¥: [CLS] æˆ‘ çˆ± åŒ—äº¬ [SEP]
        â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’  (åŒå‘æ³¨æ„åŠ›)
  
Decoder-Only (GPT):
  è¾“å…¥: æˆ‘ çˆ± åŒ—äº¬
        â†’â†’â†’â†’â†’â†’â†’â†’â†’â†’  (å•å‘æ³¨æ„åŠ›ï¼Œåªçœ‹å·¦è¾¹)
        
Encoder-Decoder (T5):
  Encoder: [ç†è§£è¾“å…¥] â”€â”€â†’ Decoder: [ç”Ÿæˆè¾“å‡º]
```

### 1.3 å¤§æ¨¡å‹è®­ç»ƒæµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                å¤§æ¨¡å‹è®­ç»ƒä¸‰é˜¶æ®µ                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  é˜¶æ®µä¸€ï¼šé¢„è®­ç»ƒ (Pre-training)                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  æ•°æ®ï¼šTBçº§äº’è”ç½‘æ–‡æœ¬ï¼ˆç½‘é¡µã€ä¹¦ç±ã€ä»£ç ...ï¼‰         â”‚   â”‚
â”‚  â”‚  ç›®æ ‡ï¼šNext Token Predictionï¼ˆé¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼‰        â”‚   â”‚
â”‚  â”‚  è§„æ¨¡ï¼šæ•°åƒGPUï¼Œè®­ç»ƒæ•°å‘¨åˆ°æ•°æœˆ                       â”‚   â”‚
â”‚  â”‚  äº§å‡ºï¼šBase Modelï¼ˆåŸºåº§æ¨¡å‹ï¼‰                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â†“                              â”‚
â”‚  é˜¶æ®µäºŒï¼šç›‘ç£å¾®è°ƒ (Supervised Fine-Tuning, SFT)         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  æ•°æ®ï¼šé«˜è´¨é‡æŒ‡ä»¤-å›ç­”å¯¹ï¼ˆ10ä¸‡~100ä¸‡æ¡ï¼‰            â”‚   â”‚
â”‚  â”‚  ç›®æ ‡ï¼šå­¦ä¹ éµå¾ªæŒ‡ä»¤ã€ç”Ÿæˆæœ‰å¸®åŠ©çš„å›ç­”              â”‚   â”‚
â”‚  â”‚  äº§å‡ºï¼šSFT Model                                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â†“                              â”‚
â”‚  é˜¶æ®µä¸‰ï¼šå¯¹é½è®­ç»ƒ (Alignment)                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  æ–¹æ³•ï¼šRLHF / DPO / RLAIF                          â”‚   â”‚
â”‚  â”‚  ç›®æ ‡ï¼šä¸äººç±»åå¥½å¯¹é½ï¼Œå®‰å…¨ã€æœ‰å¸®åŠ©ã€è¯šå®           â”‚   â”‚
â”‚  â”‚  äº§å‡ºï¼šChat Modelï¼ˆå¯å¯¹è¯çš„æ¨¡å‹ï¼‰                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.4 é¢„è®­ç»ƒå…³é”®æŠ€æœ¯

#### 1.4.1 æ³¨æ„åŠ›æœºåˆ¶ä¼˜åŒ–

| æŠ€æœ¯ | åŸç† | ä¼˜åŠ¿ |
|------|------|------|
| **Multi-Head Attention** | å¤šä¸ªæ³¨æ„åŠ›å¤´å¹¶è¡Œè®¡ç®— | æ•æ‰ä¸åŒå­ç©ºé—´çš„ä¿¡æ¯ |
| **Flash Attention** | IO-aware ç²¾ç¡®æ³¨æ„åŠ›ç®—æ³• | æ˜¾å­˜å‡å°‘ï¼Œé€Ÿåº¦æå‡ 2-4x |
| **GQA (Grouped Query)** | KV Cache åˆ†ç»„å…±äº« | æ¨ç†æ•ˆç‡æå‡ |
| **MQA (Multi-Query)** | æ‰€æœ‰å¤´å…±äº« KV | æè‡´æ¨ç†æ•ˆç‡ |
| **Sliding Window** | å±€éƒ¨æ³¨æ„åŠ›çª—å£ | æ”¯æŒæ›´é•¿ä¸Šä¸‹æ–‡ |

#### 1.4.2 ä½ç½®ç¼–ç 

```python
# ä¸»æµä½ç½®ç¼–ç æ–¹æ¡ˆ

ä½ç½®ç¼–ç æ–¹æ¡ˆå¯¹æ¯”ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ–¹æ¡ˆ           â”‚ ç‰¹ç‚¹                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ç»å¯¹ä½ç½®ç¼–ç     â”‚ ç®€å•ï¼Œä½†å¤–æ¨èƒ½åŠ›å·®                   â”‚
â”‚ (Sinusoidal)   â”‚ ç”¨äºåŸå§‹ Transformer                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ å¯å­¦ä¹ ä½ç½®ç¼–ç   â”‚ GPT ç³»åˆ—é‡‡ç”¨                        â”‚
â”‚ (Learned)      â”‚ çµæ´»ä½†æ³›åŒ–å—é™äºè®­ç»ƒé•¿åº¦             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ RoPE           â”‚ LLaMA/Qwen é‡‡ç”¨                     â”‚
â”‚ (æ—‹è½¬ä½ç½®ç¼–ç )  â”‚ å¤–æ¨èƒ½åŠ›å¼ºï¼Œæ”¯æŒé•¿æ–‡æœ¬               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ALiBi          â”‚ BLOOM é‡‡ç”¨                          â”‚
â”‚ (çº¿æ€§åç½®)      â”‚ æ— éœ€è®­ç»ƒï¼Œå¤–æ¨èƒ½åŠ›å¥½                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 1.4.3 è®­ç»ƒä¼˜åŒ–æŠ€æœ¯

| æŠ€æœ¯ | ä½œç”¨ | è¯´æ˜ |
|------|------|------|
| **æ··åˆç²¾åº¦è®­ç»ƒ (FP16/BF16)** | å‡å°‘æ˜¾å­˜ï¼ŒåŠ é€Ÿè®¡ç®— | BF16 æ•°å€¼ç¨³å®šæ€§æ›´å¥½ |
| **æ¢¯åº¦ç´¯ç§¯** | æ¨¡æ‹Ÿæ›´å¤§ batch size | æ˜¾å­˜å—é™æ—¶ä½¿ç”¨ |
| **æ¢¯åº¦æ£€æŸ¥ç‚¹** | ç”¨è®¡ç®—æ¢æ˜¾å­˜ | é‡è®¡ç®—éƒ¨åˆ†æ¿€æ´»å€¼ |
| **ZeRO ä¼˜åŒ–** | åˆ†å¸ƒå¼æ˜¾å­˜ä¼˜åŒ– | DeepSpeed ä¸‰é˜¶æ®µ |
| **å¼ é‡å¹¶è¡Œ (TP)** | åˆ‡åˆ†æ¨¡å‹å±‚ | å•æœºå¤šå¡ |
| **æµæ°´çº¿å¹¶è¡Œ (PP)** | åˆ‡åˆ†æ¨¡å‹å±‚åºåˆ— | å¤šæœºè®­ç»ƒ |
| **æ•°æ®å¹¶è¡Œ (DP)** | æ•°æ®åˆ†ç‰‡ | æœ€åŸºç¡€çš„å¹¶è¡Œ |

### 1.5 é¢„è®­ç»ƒä»£ç ç¤ºä¾‹

```python
# ä½¿ç”¨ Hugging Face Transformers é¢„è®­ç»ƒç¤ºä¾‹
from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer,
    TrainingArguments,
    Trainer,
    DataCollatorForLanguageModeling
)
from datasets import load_dataset

# 1. åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
model_name = "gpt2"  # æˆ–è‡ªå®šä¹‰æ¶æ„
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name)

# 2. åŠ è½½æ•°æ®é›†
dataset = load_dataset("wikitext", "wikitext-2-raw-v1")

# 3. æ•°æ®é¢„å¤„ç†
def tokenize_function(examples):
    return tokenizer(examples["text"], truncation=True, max_length=512)

tokenized_dataset = dataset.map(tokenize_function, batched=True)

# 4. è®­ç»ƒé…ç½®
training_args = TrainingArguments(
    output_dir="./results",
    num_train_epochs=3,
    per_device_train_batch_size=8,
    gradient_accumulation_steps=4,
    learning_rate=5e-5,
    warmup_steps=500,
    weight_decay=0.01,
    fp16=True,  # æ··åˆç²¾åº¦
    logging_steps=100,
    save_steps=1000,
)

# 5. æ•°æ®æ•´ç†å™¨
data_collator = DataCollatorForLanguageModeling(
    tokenizer=tokenizer, mlm=False  # CLM ä»»åŠ¡
)

# 6. è®­ç»ƒ
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset["train"],
    data_collator=data_collator,
)

trainer.train()
```

---

## 2. å¤§æ¨¡å‹å¯¹é½ä¸ä¼˜åŒ–æŠ€æœ¯

### 2.1 ä»€ä¹ˆæ˜¯å¯¹é½ï¼ˆAlignmentï¼‰ï¼Ÿ

å¯¹é½æ˜¯æŒ‡è®©æ¨¡å‹çš„è¾“å‡ºç¬¦åˆäººç±»çš„æœŸæœ›å’Œä»·å€¼è§‚ï¼ŒåŒ…æ‹¬ï¼š
- **æœ‰å¸®åŠ©ï¼ˆHelpfulï¼‰**ï¼šæä¾›æœ‰ç”¨ã€å‡†ç¡®çš„ä¿¡æ¯
- **è¯šå®ï¼ˆHonestï¼‰**ï¼šä¸ç¼–é€ ä¿¡æ¯ï¼Œæ‰¿è®¤ä¸ç¡®å®šæ€§
- **æ— å®³ï¼ˆHarmlessï¼‰**ï¼šä¸äº§ç”Ÿæœ‰å®³ã€åè§å†…å®¹

### 2.2 RLHFï¼ˆåŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼‰

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RLHF æµç¨‹                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  Step 1: æ”¶é›†äººç±»åå¥½æ•°æ®                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Prompt â†’ æ¨¡å‹ç”Ÿæˆå¤šä¸ªå›ç­” â†’ äººç±»æ ‡æ³¨æ’åº        â”‚   â”‚
â”‚  â”‚  ä¾‹ï¼šå›ç­”A > å›ç­”B > å›ç­”C                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â†“                              â”‚
â”‚  Step 2: è®­ç»ƒå¥–åŠ±æ¨¡å‹ (Reward Model)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  è¾“å…¥ï¼š(prompt, response) â†’ è¾“å‡ºï¼šå¥–åŠ±åˆ†æ•°        â”‚   â”‚
â”‚  â”‚  å­¦ä¹ é¢„æµ‹äººç±»åå¥½                                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â†“                              â”‚
â”‚  Step 3: PPO å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  ç­–ç•¥æ¨¡å‹ç”Ÿæˆå›ç­” â†’ å¥–åŠ±æ¨¡å‹æ‰“åˆ† â†’ æ›´æ–°ç­–ç•¥       â”‚   â”‚
â”‚  â”‚  + KL æ•£åº¦çº¦æŸï¼ˆé˜²æ­¢åç¦»åŸæ¨¡å‹å¤ªè¿œï¼‰              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.3 DPOï¼ˆç›´æ¥åå¥½ä¼˜åŒ–ï¼‰

DPO æ˜¯ RLHF çš„ç®€åŒ–æ›¿ä»£æ–¹æ¡ˆï¼Œæ— éœ€å•ç‹¬è®­ç»ƒå¥–åŠ±æ¨¡å‹ã€‚

```python
# DPO æ ¸å¿ƒæ€æƒ³
"""
RLHF: SFT Model â†’ Reward Model â†’ PPO â†’ Aligned Model
DPO:  SFT Model â†’ ç›´æ¥ä¼˜åŒ– â†’ Aligned Model

DPO æŸå¤±å‡½æ•°ï¼š
L_DPO = -log Ïƒ(Î² * (log Ï€(y_w|x) - log Ï€(y_l|x) 
                    - log Ï€_ref(y_w|x) + log Ï€_ref(y_l|x)))

å…¶ä¸­ï¼š
- y_w: åå¥½çš„å›ç­” (winner)
- y_l: ä¸åå¥½çš„å›ç­” (loser)
- Ï€: å½“å‰ç­–ç•¥
- Ï€_ref: å‚è€ƒç­–ç•¥ï¼ˆSFTæ¨¡å‹ï¼‰
- Î²: æ¸©åº¦å‚æ•°
"""
```

| æ–¹æ³• | ä¼˜åŠ¿ | åŠ£åŠ¿ |
|------|------|------|
| **RLHF** | æ•ˆæœå¥½ï¼Œä¸šç•ŒéªŒè¯å……åˆ† | å¤æ‚ï¼Œéœ€è¦è®­ç»ƒå¥–åŠ±æ¨¡å‹ |
| **DPO** | ç®€å•ï¼Œæ— éœ€å¥–åŠ±æ¨¡å‹ | å¯¹æ•°æ®è´¨é‡è¦æ±‚é«˜ |
| **RLAIF** | ç”¨AIä»£æ›¿äººç±»æ ‡æ³¨ | ä¾èµ–è¾…åŠ©æ¨¡å‹è´¨é‡ |

### 2.4 æç¤ºå·¥ç¨‹ï¼ˆPrompt Engineeringï¼‰

æç¤ºå·¥ç¨‹æ˜¯ä¸€ç§æ— éœ€è®­ç»ƒå³å¯ä¼˜åŒ–æ¨¡å‹è¾“å‡ºçš„æŠ€æœ¯ã€‚

#### 2.4.1 æ ¸å¿ƒæŠ€å·§

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                æç¤ºå·¥ç¨‹æŠ€å·§å¤§å…¨                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  ğŸ­ è§’è‰²è®¾å®š (Role Prompting)                           â”‚
â”‚  "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„Pythonå¼€å‘ä¸“å®¶ï¼Œæ“…é•¿ä»£ç ä¼˜åŒ–..."          â”‚
â”‚                                                         â”‚
â”‚  ğŸ“ æŒ‡ä»¤æ¸…æ™°åŒ–                                          â”‚
â”‚  "è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œåˆ†ç‚¹åˆ—å‡ºï¼Œæ¯ç‚¹ä¸è¶…è¿‡50å­—"                â”‚
â”‚                                                         â”‚
â”‚  ğŸ“‹ æ ¼å¼çº¦æŸ                                            â”‚
â”‚  "è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼ŒåŒ…å«nameã€ageã€cityå­—æ®µ"         â”‚
â”‚                                                         â”‚
â”‚  ğŸ’¡ æ€ç»´é“¾ (Chain of Thought, CoT)                      â”‚
â”‚  "è®©æˆ‘ä»¬ä¸€æ­¥ä¸€æ­¥æ€è€ƒè¿™ä¸ªé—®é¢˜..."                         â”‚
â”‚                                                         â”‚
â”‚  ğŸ“š å°‘æ ·æœ¬å­¦ä¹  (Few-shot Learning)                      â”‚
â”‚  "ç¤ºä¾‹1ï¼šè¾“å…¥XX â†’ è¾“å‡ºYY                                â”‚
â”‚   ç¤ºä¾‹2ï¼šè¾“å…¥AA â†’ è¾“å‡ºBB                                â”‚
â”‚   ç°åœ¨è¯·å¤„ç†ï¼šè¾“å…¥CC â†’ ?"                               â”‚
â”‚                                                         â”‚
â”‚  ğŸ”„ è‡ªæˆ‘ä¸€è‡´æ€§ (Self-Consistency)                       â”‚
â”‚  å¤šæ¬¡é‡‡æ ·ï¼ŒæŠ•ç¥¨é€‰æ‹©æœ€ä¸€è‡´çš„ç­”æ¡ˆ                          â”‚
â”‚                                                         â”‚
â”‚  ğŸŒ³ æ€ç»´æ ‘ (Tree of Thoughts)                           â”‚
â”‚  æ¢ç´¢å¤šæ¡æ¨ç†è·¯å¾„ï¼Œè¯„ä¼°é€‰æ‹©æœ€ä¼˜                          â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 2.4.2 Prompt æ¨¡æ¿ç¤ºä¾‹

```python
# ç³»ç»Ÿçº§ Prompt æ¨¡æ¿
SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„{role}ï¼Œå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š
1. {characteristic_1}
2. {characteristic_2}
3. {characteristic_3}

åœ¨å›ç­”é—®é¢˜æ—¶ï¼Œè¯·éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š
- {principle_1}
- {principle_2}
- {principle_3}

è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
{output_format}
"""

# Chain of Thought æ¨¡æ¿
COT_PROMPT = """
é—®é¢˜ï¼š{question}

è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ€è€ƒï¼š
1. é¦–å…ˆï¼Œç†è§£é—®é¢˜çš„æ ¸å¿ƒæ˜¯ä»€ä¹ˆ
2. ç„¶åï¼Œåˆ†æå·²çŸ¥æ¡ä»¶
3. æ¥ç€ï¼Œåˆ¶å®šè§£å†³æ–¹æ¡ˆ
4. æœ€åï¼Œç»™å‡ºç­”æ¡ˆ

è®©æˆ‘ä»¬å¼€å§‹ï¼š
"""

# Few-shot æ¨¡æ¿
FEW_SHOT_PROMPT = """
ä»»åŠ¡ï¼š{task_description}

ç¤ºä¾‹1ï¼š
è¾“å…¥ï¼š{example_1_input}
è¾“å‡ºï¼š{example_1_output}

ç¤ºä¾‹2ï¼š
è¾“å…¥ï¼š{example_2_input}
è¾“å‡ºï¼š{example_2_output}

ç°åœ¨è¯·å¤„ç†ï¼š
è¾“å…¥ï¼š{actual_input}
è¾“å‡ºï¼š
"""
```

#### 2.4.3 é«˜çº§ Prompt æŠ€æœ¯

| æŠ€æœ¯ | è¯´æ˜ | é€‚ç”¨åœºæ™¯ |
|------|------|----------|
| **ReAct** | æ¨ç†+è¡ŒåŠ¨äº¤æ›¿ | Agent ä»»åŠ¡ |
| **Reflexion** | è‡ªæˆ‘åæ€æ”¹è¿› | å¤æ‚æ¨ç† |
| **Plan-and-Solve** | å…ˆè§„åˆ’åæ‰§è¡Œ | å¤šæ­¥éª¤ä»»åŠ¡ |
| **Least-to-Most** | ä»ç®€åˆ°ç¹åˆ†è§£ | å¤æ‚é—®é¢˜ |
| **Skeleton-of-Thought** | å…ˆéª¨æ¶åå¡«å…… | é•¿æ–‡æœ¬ç”Ÿæˆ |

---

## 3. å¤§æ¨¡å‹å¾®è°ƒ

### 3.1 å¾®è°ƒæ–¹æ³•æ¦‚è§ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  å¾®è°ƒæ–¹æ³•è°±ç³»                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  æŒ‰å‚æ•°æ›´æ–°èŒƒå›´ï¼š                                        â”‚
â”‚                                                         â”‚
â”‚  å…¨å‚æ•°å¾®è°ƒ (Full Fine-tuning)                          â”‚
â”‚  â”œâ”€â”€ æ›´æ–°æ‰€æœ‰å‚æ•°                                       â”‚
â”‚  â”œâ”€â”€ æ•ˆæœæœ€å¥½ï¼Œä½†æˆæœ¬æœ€é«˜                               â”‚
â”‚  â””â”€â”€ éœ€è¦å¤§é‡æ˜¾å­˜å’Œè®¡ç®—èµ„æº                              â”‚
â”‚                                                         â”‚
â”‚  å‚æ•°é«˜æ•ˆå¾®è°ƒ (PEFT)                                    â”‚
â”‚  â”œâ”€â”€ LoRAï¼šä½ç§©é€‚é…                                     â”‚
â”‚  â”œâ”€â”€ QLoRAï¼šé‡åŒ– + LoRA                                 â”‚
â”‚  â”œâ”€â”€ Prefix Tuningï¼šå‰ç¼€è°ƒä¼˜                            â”‚
â”‚  â”œâ”€â”€ P-Tuning v2ï¼šæ·±åº¦æç¤ºè°ƒä¼˜                          â”‚
â”‚  â”œâ”€â”€ Adapterï¼šé€‚é…å™¨å±‚                                  â”‚
â”‚  â””â”€â”€ IA3ï¼šæŠ‘åˆ¶å’Œæ”¾å¤§å†…éƒ¨æ¿€æ´»                            â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 LoRA è¯¦è§£

LoRA (Low-Rank Adaptation) æ˜¯æœ€æµè¡Œçš„å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•ã€‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LoRA åŸç†                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  åŸå§‹æƒé‡çŸ©é˜µ W (d Ã— k)                                  â”‚
â”‚                                                         â”‚
â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚  x â”€â”€â†’â”‚   W (å†»ç»“)     â”‚â”€â”€â†’ y                           â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚              +                                          â”‚
â”‚       â”Œâ”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”                                â”‚
â”‚  x â”€â”€â†’â”‚  A  â”‚â”€â”€â†’â”‚  B  â”‚â”€â”€â†’ Î”y                          â”‚
â”‚       â””â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚       (d Ã— r)   (r Ã— k)                                â”‚
â”‚                                                         â”‚
â”‚  æœ€ç»ˆè¾“å‡ºï¼šy' = Wx + BAx                                â”‚
â”‚                                                         â”‚
â”‚  æ ¸å¿ƒæ€æƒ³ï¼š                                              â”‚
â”‚  - å†»ç»“åŸå§‹æƒé‡ W                                        â”‚
â”‚  - æ–°å¢ä½ç§©çŸ©é˜µ Aã€B (r &lt;&lt; d, k)                         â”‚
â”‚  - åªè®­ç»ƒ Aã€Bï¼Œå‚æ•°é‡å¤§å¹…å‡å°‘                           â”‚
â”‚  - ä¾‹ï¼šr=8 æ—¶ï¼Œå‚æ•°é‡å‡å°‘ ~10000 å€                      â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.3 å¾®è°ƒå®è·µä»£ç 

#### 3.3.1 ä½¿ç”¨ PEFT + LoRA å¾®è°ƒ

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments
from peft import LoraConfig, get_peft_model, TaskType
from trl import SFTTrainer
from datasets import load_dataset

# 1. åŠ è½½åŸºåº§æ¨¡å‹
model_name = "meta-llama/Llama-2-7b-hf"
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16,
    device_map="auto"
)
tokenizer = AutoTokenizer.from_pretrained(model_name)
tokenizer.pad_token = tokenizer.eos_token

# 2. é…ç½® LoRA
lora_config = LoraConfig(
    task_type=TaskType.CAUSAL_LM,
    r=8,                      # ä½ç§©ç»´åº¦
    lora_alpha=32,            # ç¼©æ”¾å› å­
    lora_dropout=0.1,         # Dropout
    target_modules=[          # è¦é€‚é…çš„æ¨¡å—
        "q_proj", "k_proj", "v_proj", "o_proj",
        "gate_proj", "up_proj", "down_proj"
    ],
)

# 3. åº”ç”¨ LoRA
model = get_peft_model(model, lora_config)
model.print_trainable_parameters()
# è¾“å‡ºï¼štrainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.0622

# 4. å‡†å¤‡æ•°æ®é›†
dataset = load_dataset("json", data_files="train_data.json")

def format_instruction(example):
    return f"""### æŒ‡ä»¤ï¼š
{example['instruction']}

### å›ç­”ï¼š
{example['output']}"""

# 5. è®­ç»ƒé…ç½®
training_args = TrainingArguments(
    output_dir="./lora_output",
    num_train_epochs=3,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=4,
    learning_rate=2e-4,
    fp16=True,
    logging_steps=10,
    save_strategy="epoch",
    warmup_ratio=0.03,
)

# 6. è®­ç»ƒ
trainer = SFTTrainer(
    model=model,
    args=training_args,
    train_dataset=dataset["train"],
    formatting_func=format_instruction,
    max_seq_length=512,
)

trainer.train()

# 7. ä¿å­˜ LoRA æƒé‡
model.save_pretrained("./lora_weights")
```

#### 3.3.2 ä½¿ç”¨ QLoRA å¾®è°ƒï¼ˆæ˜¾å­˜æ›´çœï¼‰

```python
from transformers import BitsAndBytesConfig
import torch

# 4-bit é‡åŒ–é…ç½®
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.float16,
    bnb_4bit_use_double_quant=True,
)

# åŠ è½½é‡åŒ–æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    quantization_config=bnb_config,
    device_map="auto"
)

# åç»­ä¸ LoRA ç›¸åŒ...
```

### 3.4 å¾®è°ƒæ–¹æ³•å¯¹æ¯”

| æ–¹æ³• | å¯è®­ç»ƒå‚æ•° | æ˜¾å­˜éœ€æ±‚ | æ•ˆæœ | æ¨èåœºæ™¯ |
|------|-----------|----------|------|----------|
| **Full Fine-tuning** | 100% | æé«˜ | æœ€å¥½ | å……è¶³èµ„æº |
| **LoRA** | ~0.1% | ä¸­ç­‰ | å¾ˆå¥½ | é€šç”¨åœºæ™¯ |
| **QLoRA** | ~0.1% | ä½ | è¾ƒå¥½ | æ˜¾å­˜å—é™ |
| **Prefix Tuning** | ~0.01% | ä½ | ä¸€èˆ¬ | ç®€å•ä»»åŠ¡ |
| **Adapter** | ~1% | ä¸­ä½ | è¾ƒå¥½ | å¤šä»»åŠ¡ |

### 3.5 å¾®è°ƒæ•°æ®æ ¼å¼

```python
# Alpaca æ ¼å¼ï¼ˆæœ€å¸¸ç”¨ï¼‰
{
    "instruction": "å°†ä»¥ä¸‹å¥å­ç¿»è¯‘æˆè‹±æ–‡",
    "input": "ä»Šå¤©å¤©æ°”å¾ˆå¥½",
    "output": "The weather is nice today."
}

# ShareGPT æ ¼å¼ï¼ˆå¤šè½®å¯¹è¯ï¼‰
{
    "conversations": [
        {"from": "human", "value": "ä½ å¥½"},
        {"from": "gpt", "value": "ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ"},
        {"from": "human", "value": "ä»‹ç»ä¸€ä¸‹åŒ—äº¬"},
        {"from": "gpt", "value": "åŒ—äº¬æ˜¯ä¸­å›½çš„é¦–éƒ½..."}
    ]
}

# OpenAI æ ¼å¼
{
    "messages": [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹"},
        {"role": "user", "content": "ä½ å¥½"},
        {"role": "assistant", "content": "ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„ï¼Ÿ"}
    ]
}
```

---

## 4. å¤§æ¨¡å‹æ¨ç†ä¸éƒ¨ç½²

### 4.1 æ¨ç†ä¼˜åŒ–æŠ€æœ¯

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 æ¨ç†ä¼˜åŒ–æŠ€æœ¯æ ˆ                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  ğŸ”¢ æ¨¡å‹å‹ç¼©                                            â”‚
â”‚  â”œâ”€â”€ é‡åŒ– (Quantization)                               â”‚
â”‚  â”‚   â”œâ”€â”€ INT8ï¼šç²¾åº¦æŸå¤±å°ï¼Œæ¨ç†å¿« 2x                    â”‚
â”‚  â”‚   â”œâ”€â”€ INT4ï¼šç²¾åº¦æœ‰æŸï¼Œæ˜¾å­˜çœ 4x                      â”‚
â”‚  â”‚   â””â”€â”€ GPTQ/AWQ/GGUFï¼šä¸åŒé‡åŒ–æ–¹æ¡ˆ                   â”‚
â”‚  â”œâ”€â”€ å‰ªæ (Pruning)                                    â”‚
â”‚  â”‚   â””â”€â”€ ç§»é™¤ä¸é‡è¦çš„å‚æ•°                               â”‚
â”‚  â””â”€â”€ è’¸é¦ (Distillation)                               â”‚
â”‚      â””â”€â”€ å¤§æ¨¡å‹çŸ¥è¯†è¿ç§»åˆ°å°æ¨¡å‹                          â”‚
â”‚                                                         â”‚
â”‚  âš¡ æ¨ç†åŠ é€Ÿ                                            â”‚
â”‚  â”œâ”€â”€ KV Cacheï¼šç¼“å­˜æ³¨æ„åŠ›é”®å€¼å¯¹                         â”‚
â”‚  â”œâ”€â”€ Flash Attentionï¼šé«˜æ•ˆæ³¨æ„åŠ›è®¡ç®—                   â”‚
â”‚  â”œâ”€â”€ Continuous Batchingï¼šåŠ¨æ€æ‰¹å¤„ç†                   â”‚
â”‚  â”œâ”€â”€ Speculative Decodingï¼šæ¨æµ‹è§£ç                     â”‚
â”‚  â””â”€â”€ PagedAttentionï¼šåˆ†é¡µæ³¨æ„åŠ› (vLLM)                 â”‚
â”‚                                                         â”‚
â”‚  ğŸ–¥ï¸ ç¡¬ä»¶ä¼˜åŒ–                                           â”‚
â”‚  â”œâ”€â”€ TensorRTï¼šNVIDIA GPU ä¼˜åŒ–                         â”‚
â”‚  â”œâ”€â”€ ONNX Runtimeï¼šè·¨å¹³å°åŠ é€Ÿ                          â”‚
â”‚  â””â”€â”€ ç®—å­èåˆï¼šå‡å°‘å†…å­˜è®¿é—®                             â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 é‡åŒ–è¯¦è§£

| é‡åŒ–æ ¼å¼ | ä½æ•° | æ˜¾å­˜èŠ‚çœ | ç²¾åº¦æŸå¤± | é€‚ç”¨åœºæ™¯ |
|----------|------|----------|----------|----------|
| **FP16** | 16-bit | 2x | å‡ ä¹æ—  | è®­ç»ƒ/æ¨ç† |
| **BF16** | 16-bit | 2x | å‡ ä¹æ—  | è®­ç»ƒ/æ¨ç† |
| **INT8** | 8-bit | 4x | å¾ˆå° | æ¨ç† |
| **INT4** | 4-bit | 8x | è¾ƒå° | æ¨ç† |
| **GPTQ** | 4-bit | 8x | å° | GPU æ¨ç† |
| **AWQ** | 4-bit | 8x | æ›´å° | GPU æ¨ç† |
| **GGUF** | 2-8bit | å¯å˜ | å¯å˜ | CPU/æ··åˆæ¨ç† |

```python
# ä½¿ç”¨ bitsandbytes é‡åŒ–åŠ è½½
from transformers import AutoModelForCausalLM, BitsAndBytesConfig

# INT8 é‡åŒ–
model_8bit = AutoModelForCausalLM.from_pretrained(
    "meta-llama/Llama-2-7b-hf",
    load_in_8bit=True,
    device_map="auto"
)

# INT4 é‡åŒ–
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.float16,
)
model_4bit = AutoModelForCausalLM.from_pretrained(
    "meta-llama/Llama-2-7b-hf",
    quantization_config=bnb_config,
    device_map="auto"
)
```

### 4.3 éƒ¨ç½²æ–¹æ¡ˆ

#### 4.3.1 éƒ¨ç½²æ¡†æ¶å¯¹æ¯”

| æ¡†æ¶ | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|------|----------|
| **vLLM** | PagedAttentionï¼Œååé‡é«˜ | é«˜å¹¶å‘åœ¨çº¿æœåŠ¡ |
| **TGI** | HuggingFace å®˜æ–¹ï¼ŒåŠŸèƒ½å…¨é¢ | ç”Ÿäº§ç¯å¢ƒ |
| **Ollama** | ç®€å•æ˜“ç”¨ï¼Œæœ¬åœ°éƒ¨ç½² | ä¸ªäºº/å¼€å‘ |
| **llama.cpp** | çº¯ CPU æ¨ç†ï¼Œè·¨å¹³å° | è¾¹ç¼˜è®¾å¤‡ |
| **TensorRT-LLM** | NVIDIA ä¼˜åŒ–ï¼Œæè‡´æ€§èƒ½ | é«˜æ€§èƒ½ GPU |
| **OpenLLM** | çµæ´»ï¼Œæ”¯æŒå¤šæ¨¡å‹ | æ¨¡å‹æœåŠ¡åŒ– |

#### 4.3.2 vLLM éƒ¨ç½²ç¤ºä¾‹

```python
# å®‰è£…ï¼špip install vllm

from vllm import LLM, SamplingParams

# 1. åŠ è½½æ¨¡å‹
llm = LLM(
    model="meta-llama/Llama-2-7b-chat-hf",
    tensor_parallel_size=1,  # GPU æ•°é‡
    dtype="float16",
    max_model_len=4096,
)

# 2. è®¾ç½®é‡‡æ ·å‚æ•°
sampling_params = SamplingParams(
    temperature=0.7,
    top_p=0.9,
    max_tokens=512,
)

# 3. æ¨ç†
prompts = ["è¯·ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½", "Pythonæœ‰ä»€ä¹ˆä¼˜ç‚¹ï¼Ÿ"]
outputs = llm.generate(prompts, sampling_params)

for output in outputs:
    print(output.outputs[0].text)
```

```bash
# vLLM å¯åŠ¨ API æœåŠ¡
python -m vllm.entrypoints.openai.api_server \
    --model meta-llama/Llama-2-7b-chat-hf \
    --port 8000 \
    --tensor-parallel-size 1
```

#### 4.3.3 Ollama æœ¬åœ°éƒ¨ç½²

```bash
# å®‰è£… Ollama
curl -fsSL https://ollama.com/install.sh | sh

# ä¸‹è½½å¹¶è¿è¡Œæ¨¡å‹
ollama pull llama3
ollama run llama3

# ä½¿ç”¨ API
curl http://localhost:11434/api/generate -d '{
  "model": "llama3",
  "prompt": "ä»€ä¹ˆæ˜¯å¤§è¯­è¨€æ¨¡å‹ï¼Ÿ"
}'
```

```python
# Python è°ƒç”¨ Ollama
import ollama

response = ollama.chat(
    model='llama3',
    messages=[{'role': 'user', 'content': 'ä½ å¥½'}]
)
print(response['message']['content'])
```

### 4.4 éƒ¨ç½²æ¶æ„è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ç”Ÿäº§çº§ LLM éƒ¨ç½²æ¶æ„                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  ç”¨æˆ·è¯·æ±‚                                               â”‚
â”‚      â†“                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚  â”‚   API ç½‘å…³   â”‚  â† è®¤è¯ã€é™æµã€è·¯ç”±                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚         â”‚                                              â”‚
â”‚         â†“                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚  â”‚  è´Ÿè½½å‡è¡¡   â”‚  â† åˆ†å‘è¯·æ±‚åˆ°ä¸åŒå®ä¾‹                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚         â”‚                                              â”‚
â”‚    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”                                         â”‚
â”‚    â†“         â†“                                         â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”                                     â”‚
â”‚ â”‚æ¨ç†1 â”‚ â”‚æ¨ç†2 â”‚  â† vLLM/TGI å®ä¾‹                     â”‚
â”‚ â”‚(GPU) â”‚ â”‚(GPU) â”‚                                     â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜                                     â”‚
â”‚    â†‘         â†‘                                         â”‚
â”‚    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                         â”‚
â”‚         â”‚                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚  â”‚  æ¨¡å‹å­˜å‚¨   â”‚  â† S3/æœ¬åœ°/æ¨¡å‹ä»“åº“                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚                                                         â”‚
â”‚  ç›‘æ§ç»„ä»¶ï¼šPrometheus + Grafana                         â”‚
â”‚  æ—¥å¿—ç»„ä»¶ï¼šELK Stack                                    â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5. å…¶ä»–è®­ç»ƒä¸ä¼˜åŒ–ç›¸å…³çŸ¥è¯†

### 5.1 æ•°æ®å·¥ç¨‹

#### 5.1.1 æ•°æ®è´¨é‡çš„é‡è¦æ€§

```
æ•°æ®è´¨é‡é‡‘å­—å¡”ï¼š

        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ é«˜è´¨é‡  â”‚  â† äººå·¥æ ‡æ³¨ã€ä¸“å®¶æ ¡éªŒ
        â”‚  æ•°æ®   â”‚     æ•ˆæœæœ€å¥½ï¼Œæˆæœ¬æœ€é«˜
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ åˆæˆæ•°æ® â”‚  â† GPT-4 ç”Ÿæˆã€è‡ªæˆ‘æŒ‡ä»¤
        â”‚         â”‚     å¹³è¡¡æ•ˆæœä¸æˆæœ¬
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ ç½‘ç»œæ•°æ® â”‚  â† CommonCrawlã€ç½‘é¡µçˆ¬å–
        â”‚         â”‚     é‡å¤§è´¨ä½ï¼Œéœ€è¦æ¸…æ´—
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 5.1.2 æ•°æ®å¤„ç†æµç¨‹

```python
# æ•°æ®å¤„ç† Pipeline
data_pipeline = {
    "1. æ•°æ®æ”¶é›†": [
        "çˆ¬å–ç½‘é¡µæ•°æ®",
        "æ”¶é›†å¼€æºæ•°æ®é›†",
        "ç”Ÿæˆåˆæˆæ•°æ®"
    ],
    "2. æ•°æ®æ¸…æ´—": [
        "å»é‡ï¼ˆMinHashã€SimHashï¼‰",
        "è¿‡æ»¤ä½è´¨é‡å†…å®¹",
        "ç§»é™¤æœ‰å®³/æ•æ„Ÿä¿¡æ¯",
        "è¯­è¨€æ£€æµ‹ä¸åˆ†ç±»"
    ],
    "3. æ•°æ®å¤„ç†": [
        "åˆ†è¯ Tokenization",
        "æ ¼å¼æ ‡å‡†åŒ–",
        "é•¿åº¦è£å‰ª/å¡«å……"
    ],
    "4. æ•°æ®å¢å¼º": [
        "å›è¯‘å¢å¼º",
        "åŒä¹‰è¯æ›¿æ¢",
        "æ¨¡å‹æ”¹å†™"
    ],
    "5. è´¨é‡è¯„ä¼°": [
        "å›°æƒ‘åº¦è¯„ä¼°",
        "äººå·¥æŠ½æ ·æ£€æŸ¥",
        "å¤šæ ·æ€§åˆ†æ"
    ]
}
```

### 5.2 è¯„ä¼°ä¸æµ‹è¯•

#### 5.2.1 å¸¸ç”¨è¯„ä¼°åŸºå‡†

| åŸºå‡† | è¯„ä¼°èƒ½åŠ› | è¯´æ˜ |
|------|----------|------|
| **MMLU** | å¤šä»»åŠ¡çŸ¥è¯† | 57ä¸ªå­¦ç§‘çš„é€‰æ‹©é¢˜ |
| **HellaSwag** | å¸¸è¯†æ¨ç† | å¥å­è¡¥å…¨ |
| **GSM8K** | æ•°å­¦æ¨ç† | å°å­¦æ•°å­¦åº”ç”¨é¢˜ |
| **HumanEval** | ä»£ç ç”Ÿæˆ | Python å‡½æ•°è¡¥å…¨ |
| **TruthfulQA** | çœŸå®æ€§ | æ£€æµ‹å¹»è§‰ |
| **MT-Bench** | å¯¹è¯èƒ½åŠ› | å¤šè½®å¯¹è¯è¯„åˆ† |
| **C-Eval** | ä¸­æ–‡çŸ¥è¯† | ä¸­æ–‡å¤šä»»åŠ¡ |
| **CMMLU** | ä¸­æ–‡ MMLU | ä¸­æ–‡ç‰ˆ MMLU |

#### 5.2.2 è¯„ä¼°ä»£ç ç¤ºä¾‹

```python
# ä½¿ç”¨ lm-evaluation-harness è¯„ä¼°
# pip install lm-eval

from lm_eval import evaluator
from lm_eval.models.huggingface import HFLM

# åŠ è½½æ¨¡å‹
model = HFLM(
    pretrained="meta-llama/Llama-2-7b-hf",
    device="cuda"
)

# è¿è¡Œè¯„ä¼°
results = evaluator.simple_evaluate(
    model=model,
    tasks=["hellaswag", "mmlu", "gsm8k"],
    num_fewshot=5,
    batch_size=8
)

print(results["results"])
```

### 5.3 å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

| é—®é¢˜ | åŸå›  | è§£å†³æ–¹æ¡ˆ |
|------|------|----------|
| **è®­ç»ƒä¸æ”¶æ•›** | å­¦ä¹ ç‡ä¸å½“ã€æ•°æ®é—®é¢˜ | è°ƒæ•´ LRã€æ£€æŸ¥æ•°æ® |
| **è¿‡æ‹Ÿåˆ** | æ•°æ®é‡ä¸è¶³ã€æ¨¡å‹è¿‡å¤§ | æ•°æ®å¢å¼ºã€æ­£åˆ™åŒ– |
| **ç¾éš¾æ€§é—å¿˜** | å¾®è°ƒç ´ååŸæœ‰èƒ½åŠ› | LoRAã€è¾ƒå°å­¦ä¹ ç‡ |
| **å¹»è§‰** | è®­ç»ƒæ•°æ®æœ‰å™ªå£° | RAG å¢å¼ºã€RLHF |
| **æ¨ç†æ…¢** | æ¨¡å‹å¤§ã€ç¡¬ä»¶å¼± | é‡åŒ–ã€è’¸é¦ã€å‡çº§ç¡¬ä»¶ |
| **æ˜¾å­˜ä¸è¶³** | æ¨¡å‹/batch å¤ªå¤§ | æ¢¯åº¦ç´¯ç§¯ã€é‡åŒ–ã€LoRA |

### 5.4 è®­ç»ƒèµ„æºä¼°ç®—

```python
# æ˜¾å­˜ä¼°ç®—å…¬å¼ï¼ˆè¿‘ä¼¼ï¼‰
def estimate_memory(params_billion, precision="fp16", training=True):
    """
    params_billion: å‚æ•°é‡ï¼ˆåäº¿ï¼‰
    precision: fp32/fp16/int8/int4
    training: æ˜¯å¦è®­ç»ƒ
    """
    bytes_per_param = {
        "fp32": 4,
        "fp16": 2,
        "bf16": 2,
        "int8": 1,
        "int4": 0.5
    }
    
    # æ¨¡å‹æƒé‡
    model_memory = params_billion * bytes_per_param[precision]
    
    if training:
        # è®­ç»ƒæ—¶éœ€è¦é¢å¤–çš„ä¼˜åŒ–å™¨çŠ¶æ€å’Œæ¢¯åº¦
        # AdamW: å‚æ•° + æ¢¯åº¦ + ä¸€é˜¶åŠ¨é‡ + äºŒé˜¶åŠ¨é‡ â‰ˆ 4x
        # åŠ ä¸Šæ¿€æ´»å€¼ç­‰ï¼Œæ€»è®¡çº¦ 6-8x
        total_memory = model_memory * 6
    else:
        # æ¨ç†æ—¶ä¸»è¦æ˜¯æ¨¡å‹æƒé‡ + KV Cache
        total_memory = model_memory * 1.2
    
    return f"{total_memory:.1f} GB"

# ç¤ºä¾‹
print(estimate_memory(7, "fp16", training=True))   # çº¦ 84 GB
print(estimate_memory(7, "fp16", training=False))  # çº¦ 16.8 GB
print(estimate_memory(7, "int4", training=False))  # çº¦ 4.2 GB
```

### 5.5 è®­ç»ƒå·¥å…·ç”Ÿæ€

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  è®­ç»ƒå·¥å…·ç”Ÿæ€                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  ğŸ”§ è®­ç»ƒæ¡†æ¶                                            â”‚
â”‚  â”œâ”€â”€ Hugging Face Transformers                         â”‚
â”‚  â”œâ”€â”€ DeepSpeed                                         â”‚
â”‚  â”œâ”€â”€ Megatron-LM                                       â”‚
â”‚  â”œâ”€â”€ ColossalAI                                        â”‚
â”‚  â””â”€â”€ LLaMA-Factory                                     â”‚
â”‚                                                         â”‚
â”‚  ğŸ“Š å®éªŒç®¡ç†                                            â”‚
â”‚  â”œâ”€â”€ Weights &amp; Biases                                  â”‚
â”‚  â”œâ”€â”€ MLflow                                            â”‚
â”‚  â””â”€â”€ TensorBoard                                       â”‚
â”‚                                                         â”‚
â”‚  ğŸ—ƒï¸ æ•°æ®å¤„ç†                                           â”‚
â”‚  â”œâ”€â”€ Datasets (HuggingFace)                            â”‚
â”‚  â”œâ”€â”€ Apache Spark                                      â”‚
â”‚  â””â”€â”€ Dask                                              â”‚
â”‚                                                         â”‚
â”‚  â˜ï¸ äº‘å¹³å°                                              â”‚
â”‚  â”œâ”€â”€ AWS SageMaker                                     â”‚
â”‚  â”œâ”€â”€ Google Vertex AI                                  â”‚
â”‚  â”œâ”€â”€ Azure ML                                          â”‚
â”‚  â””â”€â”€ AutoDL / æ’æºäº‘ï¼ˆå›½å†…ï¼‰                            â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 6. æ€»ç»“

### 6.1 æ ¸å¿ƒè¦ç‚¹

| ä¸»é¢˜ | å…³é”®ç‚¹ |
|------|--------|
| **æ¶æ„ä¸è®­ç»ƒ** | Transformer æ¶æ„ã€é¢„è®­ç»ƒä¸‰é˜¶æ®µã€åˆ†å¸ƒå¼è®­ç»ƒ |
| **å¯¹é½ä¸ä¼˜åŒ–** | RLHF/DPO å¯¹é½ã€æç¤ºå·¥ç¨‹æŠ€å·§ |
| **å¾®è°ƒæŠ€æœ¯** | LoRA/QLoRA å‚æ•°é«˜æ•ˆå¾®è°ƒã€æ•°æ®æ ¼å¼ |
| **æ¨ç†éƒ¨ç½²** | é‡åŒ–å‹ç¼©ã€vLLM/Ollama éƒ¨ç½²ã€æ¶æ„è®¾è®¡ |

### 6.2 å­¦ä¹ è·¯å¾„

```
åŸºç¡€ â†’ å®è·µ â†’ æ·±å…¥

1ï¸âƒ£ åŸºç¡€ç†è®º
   â€¢ Transformer æ¶æ„åŸç†
   â€¢ æ³¨æ„åŠ›æœºåˆ¶
   â€¢ é¢„è®­ç»ƒç›®æ ‡

2ï¸âƒ£ åŠ¨æ‰‹å®è·µ
   â€¢ ä½¿ç”¨ HuggingFace å¾®è°ƒæ¨¡å‹
   â€¢ å°è¯• LoRA/QLoRA
   â€¢ æœ¬åœ°éƒ¨ç½² Ollama

3ï¸âƒ£ æ·±å…¥ä¼˜åŒ–
   â€¢ åˆ†å¸ƒå¼è®­ç»ƒ
   â€¢ æ¨ç†ä¼˜åŒ–
   â€¢ ç”Ÿäº§éƒ¨ç½²
```

### 6.3 å‚è€ƒèµ„æº

- [ã€ŠAttention Is All You Needã€‹](https://arxiv.org/abs/1706.03762)
- [ã€ŠLoRA: Low-Rank Adaptationã€‹](https://arxiv.org/abs/2106.09685)
- [ã€ŠTraining language models to follow instructions with human feedbackã€‹](https://arxiv.org/abs/2203.02155)
- [Hugging Face æ–‡æ¡£](https://huggingface.co/docs)
- [vLLM é¡¹ç›®](https://github.com/vllm-project/vllm)
- [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory)
</pre>
                </article>
            </div>
        </section>

        <!-- å³ä¾§çƒ­é—¨æ–‡ç«  -->
        <aside class="popular-sidebar">
            <div class="popular-header">
                <h3>çƒ­é—¨æ–‡ç« </h3>
            </div>
            <div class="popular-list" id="popular-list">
                <!-- åŠ¨æ€ç”Ÿæˆçš„çƒ­é—¨æ–‡ç« åˆ—è¡¨ -->
            </div>
        </aside>
    </main>

    <!-- JavaScript -->
    <script src="/script.js?v=2.1.2"></script>
</body>
</html>